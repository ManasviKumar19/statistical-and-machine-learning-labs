{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e0a694-6eb9-412b-b466-40cfbaea8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb9755d-144b-4429-9e71-7771e1ddc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_genr(n):\n",
    "    p = 15\n",
    "    n1 = n2 = n // 2\n",
    "    cov_1 = np.eye(p) + 0.2\n",
    "\n",
    "    mean_class1 = np.array([3] * p)\n",
    "    mean_class2 = np.array([2] * p)\n",
    "\n",
    "    x_class1 = np.random.multivariate_normal(mean_class1, cov_1, n1)\n",
    "    x_class2 = np.random.multivariate_normal(mean_class2, cov_1, n2)\n",
    "\n",
    "    x = np.vstack([x_class1, x_class2])\n",
    "    y = np.repeat([1, 2], [n1, n2])\n",
    "\n",
    "    df = pd.DataFrame(np.column_stack([x, y]), columns=[f'x{i}' for i in range(1, p+1)] + ['y'])\n",
    "    return df\n",
    "\n",
    "generated_dataset = data_genr(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff505b6b-8b4b-4703-bf5d-fc8af51e7aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.049759</td>\n",
       "      <td>1.556235</td>\n",
       "      <td>2.397898</td>\n",
       "      <td>2.903992</td>\n",
       "      <td>3.942776</td>\n",
       "      <td>3.310605</td>\n",
       "      <td>4.037499</td>\n",
       "      <td>3.835274</td>\n",
       "      <td>4.007224</td>\n",
       "      <td>3.135375</td>\n",
       "      <td>1.915932</td>\n",
       "      <td>2.979590</td>\n",
       "      <td>1.867080</td>\n",
       "      <td>1.350044</td>\n",
       "      <td>1.520048</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.808360</td>\n",
       "      <td>2.109678</td>\n",
       "      <td>3.827392</td>\n",
       "      <td>1.887116</td>\n",
       "      <td>2.125454</td>\n",
       "      <td>2.630668</td>\n",
       "      <td>5.551094</td>\n",
       "      <td>2.276143</td>\n",
       "      <td>2.700467</td>\n",
       "      <td>3.360015</td>\n",
       "      <td>3.597011</td>\n",
       "      <td>4.868645</td>\n",
       "      <td>2.520252</td>\n",
       "      <td>2.677242</td>\n",
       "      <td>3.614518</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.961098</td>\n",
       "      <td>4.290155</td>\n",
       "      <td>3.211514</td>\n",
       "      <td>2.329142</td>\n",
       "      <td>2.694602</td>\n",
       "      <td>5.283461</td>\n",
       "      <td>3.091141</td>\n",
       "      <td>4.385692</td>\n",
       "      <td>2.732884</td>\n",
       "      <td>3.335693</td>\n",
       "      <td>3.760156</td>\n",
       "      <td>2.365514</td>\n",
       "      <td>1.980809</td>\n",
       "      <td>2.214951</td>\n",
       "      <td>3.555277</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.122626</td>\n",
       "      <td>2.687332</td>\n",
       "      <td>4.147123</td>\n",
       "      <td>1.341273</td>\n",
       "      <td>1.435214</td>\n",
       "      <td>3.022827</td>\n",
       "      <td>1.714520</td>\n",
       "      <td>4.083020</td>\n",
       "      <td>2.027983</td>\n",
       "      <td>1.483456</td>\n",
       "      <td>2.564017</td>\n",
       "      <td>4.799621</td>\n",
       "      <td>2.635820</td>\n",
       "      <td>2.153083</td>\n",
       "      <td>1.960481</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.068101</td>\n",
       "      <td>3.232945</td>\n",
       "      <td>2.849015</td>\n",
       "      <td>3.308558</td>\n",
       "      <td>3.415500</td>\n",
       "      <td>3.215971</td>\n",
       "      <td>3.032413</td>\n",
       "      <td>1.979007</td>\n",
       "      <td>2.060713</td>\n",
       "      <td>4.016058</td>\n",
       "      <td>4.164741</td>\n",
       "      <td>4.017421</td>\n",
       "      <td>0.725203</td>\n",
       "      <td>1.949126</td>\n",
       "      <td>2.568909</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.114390</td>\n",
       "      <td>2.008320</td>\n",
       "      <td>2.108734</td>\n",
       "      <td>2.320380</td>\n",
       "      <td>1.804203</td>\n",
       "      <td>3.279793</td>\n",
       "      <td>1.788327</td>\n",
       "      <td>1.043786</td>\n",
       "      <td>2.853053</td>\n",
       "      <td>1.984094</td>\n",
       "      <td>2.824951</td>\n",
       "      <td>3.327156</td>\n",
       "      <td>-0.073229</td>\n",
       "      <td>2.521240</td>\n",
       "      <td>3.536249</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.666302</td>\n",
       "      <td>1.073130</td>\n",
       "      <td>0.261264</td>\n",
       "      <td>3.362309</td>\n",
       "      <td>1.614086</td>\n",
       "      <td>2.877166</td>\n",
       "      <td>0.458971</td>\n",
       "      <td>0.658998</td>\n",
       "      <td>0.114873</td>\n",
       "      <td>1.357567</td>\n",
       "      <td>1.309768</td>\n",
       "      <td>0.731220</td>\n",
       "      <td>1.314167</td>\n",
       "      <td>3.436277</td>\n",
       "      <td>2.507507</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.482355</td>\n",
       "      <td>3.876927</td>\n",
       "      <td>1.294535</td>\n",
       "      <td>2.030604</td>\n",
       "      <td>2.696068</td>\n",
       "      <td>1.988694</td>\n",
       "      <td>2.085538</td>\n",
       "      <td>1.569763</td>\n",
       "      <td>2.506488</td>\n",
       "      <td>2.537408</td>\n",
       "      <td>1.740857</td>\n",
       "      <td>0.800607</td>\n",
       "      <td>3.370707</td>\n",
       "      <td>2.570544</td>\n",
       "      <td>2.199424</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2.033983</td>\n",
       "      <td>3.024787</td>\n",
       "      <td>1.680469</td>\n",
       "      <td>1.406459</td>\n",
       "      <td>1.620523</td>\n",
       "      <td>1.535627</td>\n",
       "      <td>0.286010</td>\n",
       "      <td>2.484191</td>\n",
       "      <td>0.510234</td>\n",
       "      <td>3.091351</td>\n",
       "      <td>2.780763</td>\n",
       "      <td>3.207334</td>\n",
       "      <td>2.255786</td>\n",
       "      <td>2.984089</td>\n",
       "      <td>2.489888</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.686812</td>\n",
       "      <td>-0.813203</td>\n",
       "      <td>0.581330</td>\n",
       "      <td>2.185036</td>\n",
       "      <td>1.779760</td>\n",
       "      <td>1.141161</td>\n",
       "      <td>1.666315</td>\n",
       "      <td>0.806252</td>\n",
       "      <td>2.411870</td>\n",
       "      <td>1.314355</td>\n",
       "      <td>-0.123607</td>\n",
       "      <td>0.429209</td>\n",
       "      <td>0.764455</td>\n",
       "      <td>1.968261</td>\n",
       "      <td>2.242863</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0   2.049759  1.556235  2.397898  2.903992  3.942776  3.310605  4.037499   \n",
       "1   2.808360  2.109678  3.827392  1.887116  2.125454  2.630668  5.551094   \n",
       "2   2.961098  4.290155  3.211514  2.329142  2.694602  5.283461  3.091141   \n",
       "3   1.122626  2.687332  4.147123  1.341273  1.435214  3.022827  1.714520   \n",
       "4   1.068101  3.232945  2.849015  3.308558  3.415500  3.215971  3.032413   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  2.114390  2.008320  2.108734  2.320380  1.804203  3.279793  1.788327   \n",
       "96  1.666302  1.073130  0.261264  3.362309  1.614086  2.877166  0.458971   \n",
       "97  4.482355  3.876927  1.294535  2.030604  2.696068  1.988694  2.085538   \n",
       "98  2.033983  3.024787  1.680469  1.406459  1.620523  1.535627  0.286010   \n",
       "99  1.686812 -0.813203  0.581330  2.185036  1.779760  1.141161  1.666315   \n",
       "\n",
       "          x8        x9       x10       x11       x12       x13       x14  \\\n",
       "0   3.835274  4.007224  3.135375  1.915932  2.979590  1.867080  1.350044   \n",
       "1   2.276143  2.700467  3.360015  3.597011  4.868645  2.520252  2.677242   \n",
       "2   4.385692  2.732884  3.335693  3.760156  2.365514  1.980809  2.214951   \n",
       "3   4.083020  2.027983  1.483456  2.564017  4.799621  2.635820  2.153083   \n",
       "4   1.979007  2.060713  4.016058  4.164741  4.017421  0.725203  1.949126   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  1.043786  2.853053  1.984094  2.824951  3.327156 -0.073229  2.521240   \n",
       "96  0.658998  0.114873  1.357567  1.309768  0.731220  1.314167  3.436277   \n",
       "97  1.569763  2.506488  2.537408  1.740857  0.800607  3.370707  2.570544   \n",
       "98  2.484191  0.510234  3.091351  2.780763  3.207334  2.255786  2.984089   \n",
       "99  0.806252  2.411870  1.314355 -0.123607  0.429209  0.764455  1.968261   \n",
       "\n",
       "         x15    y  \n",
       "0   1.520048  1.0  \n",
       "1   3.614518  1.0  \n",
       "2   3.555277  1.0  \n",
       "3   1.960481  1.0  \n",
       "4   2.568909  1.0  \n",
       "..       ...  ...  \n",
       "95  3.536249  2.0  \n",
       "96  2.507507  2.0  \n",
       "97  2.199424  2.0  \n",
       "98  2.489888  2.0  \n",
       "99  2.242863  2.0  \n",
       "\n",
       "[100 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696479c-1bec-46b4-9100-b44293784901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80767125-03e5-4b07-b2f1-420a5fa3c34e",
   "metadata": {},
   "source": [
    "## Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb736c-9dbf-4ab6-87ef-82ce3788bb2f",
   "metadata": {},
   "source": [
    "#### Training Data 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8366e562-7ace-41f3-becc-5703f121b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_50_size = data_genr(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07562ab2-aa80-46e8-80c4-d5b61b415337",
   "metadata": {},
   "source": [
    "#### Training Data 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49c57b8b-10db-4c52-b99a-2791b6171f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_10000_size = data_genr(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcafa83b-7653-459c-8900-867323a18e04",
   "metadata": {},
   "source": [
    "#### Testing Data 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70162418-1ef4-46ee-9a5b-ba97c8c940e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_10000_size = data_genr(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27b76a-3824-4085-9537-49d72aa8faf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48803885-4280-4228-8639-8c2a2f0cb09a",
   "metadata": {},
   "source": [
    "## Performance of LDA and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b8762-7052-48bc-8dc4-5fe957d642f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea210e9-8cbe-493c-9f64-fbb9ed234678",
   "metadata": {},
   "source": [
    "### Logistic Regression Small Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5fa7ce2-4397-48b1-a39b-ca0f2fab58d3",
   "metadata": {},
   "source": [
    "Small Dataset:-\n",
    "Bias: LR makes less assumptions about the overall data distribution. It can be more flexible in capturing higher relationships. However with less data bias might be present.\n",
    "\n",
    "Variance: With a small training set, LR might be more prone to overfitting, resulting in higher variance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5863c34e-41b1-445d-99da-766de6b46ef8",
   "metadata": {},
   "source": [
    "### Logistic Regression Large Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da2816cd-5bb2-4160-bd9d-a7279f4c9882",
   "metadata": {},
   "source": [
    "Large Dataset:-\n",
    "Bias: With more data, LR may have a better chance of capturing the underlying patterns in the data, potentially leading to lower bias.\n",
    "\n",
    "Variance: With a larger training set, LR is likely to have lower variance as it has more examples to learn from.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a718c15-4207-4147-8172-85c5a6cde057",
   "metadata": {},
   "source": [
    "### LDA Large Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c25e093-67f8-4b54-994a-05541eae0b95",
   "metadata": {},
   "source": [
    "Small Dataset:-\n",
    "Bias: LDA assumes a proper distribution of the data. If the assumptions are valid, then LDA may have lower bias compared to LR. \n",
    "Variance: LDA tends to have lower variance than LR, especially when the assumptions about the data distribution are met.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ee364-b6e4-4eba-8676-5d64de16f3cc",
   "metadata": {},
   "source": [
    "### LDA Small Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfc043ea-9870-4783-9787-46c51ac8bae3",
   "metadata": {},
   "source": [
    "Large Dataset:-\n",
    "Bias: LDA may continue to have low bias, assuming the distribution assumptions hold even with a larger training set.\n",
    "Variance: LDA's variance may also decrease with more data, but with more data it might work same as  LR ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26a237-9407-4516-bdc3-f5d2b4af3a88",
   "metadata": {},
   "source": [
    "## Training and Evaluating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf899b-7284-4235-b8f1-3bb593bf9f44",
   "metadata": {},
   "source": [
    "### LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c37fd2-d3ad-49b2-af1a-09ef8bb4f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_model_func(train_data, test_data, reps):\n",
    "    lda_results = []\n",
    "    for r in range(reps):\n",
    "        train_data_func = data_genr(train_data)\n",
    "        X_train = train_data_func.iloc[:, :-1]\n",
    "        y_train = train_data_func['y']\n",
    "\n",
    "        test_set_func = data_genr(test_data)\n",
    "        X_test = test_set_func.iloc[:, :-1]\n",
    "        y_test = test_set_func['y']\n",
    "        \n",
    "        lda_Model = LinearDiscriminantAnalysis()\n",
    "        lda_Model.fit(X_train, y_train)\n",
    "        lda_pred_res = lda_Model.predict(X_test)\n",
    "        lda_accuracy = balanced_accuracy_score(y_test, lda_pred_res)\n",
    "        lda_results.append(lda_accuracy)\n",
    "    lda_avg_accuracy = np.mean(lda_results)\n",
    "    return lda_avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1fa3b-134c-47aa-8664-11b00a53530d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19fda671-8484-4ca8-8df1-a475913add01",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205f4768-bd8d-4aab-9d12-e26e2154378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoRe_model_func(train_data, test_data, reps):\n",
    "    LR_results = []\n",
    "    for r in range(reps):\n",
    "        train_data_func = data_genr(train_data)\n",
    "        X_train = train_data_func.iloc[:, :-1]\n",
    "        y_train = train_data_func['y']\n",
    "\n",
    "        test_set_func = data_genr(test_data)\n",
    "        X_test = test_set_func.iloc[:, :-1]\n",
    "        y_test = test_set_func['y']\n",
    "\n",
    "        LR_model = LogisticRegression()\n",
    "        LR_model.fit(X_train, y_train)\n",
    "        lr_pred_res = LR_model.predict(X_test)\n",
    "        lr_accuracy = balanced_accuracy_score(y_test, lr_pred_res)\n",
    "        LR_results.append(lr_accuracy)\n",
    "\n",
    "    \n",
    "    LR_avg_accuracy = np.mean(LR_results)\n",
    "\n",
    "    return LR_avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142ac88-cce5-4b5a-b3d7-5082c12ff589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66e9dc3c-beb2-48b0-9f9f-5ad89694eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitions = 100\n",
    "train_data_size_50 = 50\n",
    "train_data_size_10000 = 10000\n",
    "test_data_size_10000 = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f7f04-d707-4b03-b3b2-caf158615e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d5d47a-be82-4c96-add2-043ada1c9794",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_avg_size_50 = LDA_model_func(train_data_size_50,test_data_size_10000,repetitions)\n",
    "\n",
    "LDA_avg_size_10000 = LDA_model_func(train_data_size_10000,test_data_size_10000,repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670241d-832c-45eb-b861-ec2dd15fed97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5363b975-e2d9-47af-a83e-e36d0c3a729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_avg_size_50 = LoRe_model_func(train_data_size_50,test_data_size_10000,repetitions)\n",
    "\n",
    "LR_avg_size_10000 = LoRe_model_func(train_data_size_10000,test_data_size_10000,repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d1e63-cf3a-4519-8761-4647372ff8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35ed45cd-73d4-4317-b376-56a7dfe2057a",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102135a6-403d-41f1-a1ba-03b1f503d843",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0525f273-74ae-41f1-bc0f-5ae1f3cac318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average LDA Balanced Accuracy (Training Set Size 50): 0.7592110000000001\n",
      "Average LDA Balanced Accuracy (Training Set Size 10000): 0.832385\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average LDA Balanced Accuracy (Training Set Size 50): {LDA_avg_size_50}\")\n",
    "print(f\"Average LDA Balanced Accuracy (Training Set Size 10000): {LDA_avg_size_10000}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3f86b-318c-48cf-a55d-e274a6679dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e874bed-c5ae-4bb2-88a8-0ddac9253202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Logistic Regression Balanced Accuracy (Training Set Size 50): 0.7848979999999999\n",
      "Average Logistic Regression Balanced Accuracy (Training Set Size 10000): 0.8334380000000001\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Logistic Regression Balanced Accuracy (Training Set Size 50): {LR_avg_size_50}\")\n",
    "print(f\"Average Logistic Regression Balanced Accuracy (Training Set Size 10000): {LR_avg_size_10000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f676826-82ef-4b0b-aa2f-b96f3738c222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1ef85fc-8644-4d3b-a6c7-ca58d8223517",
   "metadata": {},
   "source": [
    "## Result analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891670f-4a18-4781-bbf5-82d5a4d42faa",
   "metadata": {},
   "source": [
    "### LR and LDA Training Set Size 50:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7dfc529-454b-4b37-b36c-4e7ca99480ab",
   "metadata": {},
   "source": [
    "Training Set Size 50:\n",
    "\n",
    "The higher balanced accuracy for logistic regression compared to LDA is as per the expectations. In a small training set, logistic regression's flexibility is advantageous in capturing complex relationships, resulting in slightly better performance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6e7ae5e-ad6a-42da-96a7-45ec3146c68b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "935fa088-c263-4659-8d09-08bd180c988d",
   "metadata": {},
   "source": [
    "### LR and LDA Training Set Size 10000:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25148997-cfe4-4a39-b6f7-e9850ed9ab8e",
   "metadata": {},
   "source": [
    "Training Set Size 10000:\n",
    "\n",
    "The balanced accuracies for LDA and logistic regression are very close. With a larger training set, LDA has more data to do accurate estimates of the distributions, and logistic regression can effectively utilize the increased sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0696e-c6e3-4d99-8e2c-12659fe6ad24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01aa126-3329-4014-8ac8-3c6263570694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596adc33-4c30-4e7c-bfba-b40a77b4e251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
