# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eQBMkrV7ruc0mo-1bK4QzGNwoFlTUhRP
"""

set.seed(3938425)

install.packages("caret")

install.packages("randomForest")

library(caret)

library(mgcv)

qsar <- readRDS("qsar.Rda")

set.seed(42)
train_indices <- sample(1:nrow(qsar), size = 700)
test_indices <- which(!(1:nrow(qsar) %in% train_indices))

predictors_train <- qsar[train_indices, 1:41]  # First 41 columns are predictors
response_train <- qsar[train_indices, 42]

set.seed(123)

predictors_test <- qsar[test_indices, 1:41]  # First 41 columns are predictors
response_test <- qsar[test_indices, 42]

trained_model <- train(
  x = predictors_train,  # predictors_train: Training predictors
  y = response_train,    # response_train: Training response
  method = "gbm",        # Method: Gradient Boosting Machine
  tuneGrid = grid,       # Parameter grid for tuning
  distribution = "bernoulli",  # Distribution for classification
  trControl = trainControl(method = "cv", number = 10)
)



plot(trained_model)



"""Q) Describe the main effects of the shrinkage, n.trees and interaction.depth parameters on the
accuracy of the model. Also describe their possible interactions

Ans:- Shrinkage: Shrinkage controls the learning rate of the boosting process. A smaller shrinkage means each tree contributes less to the final prediction. Generally, smaller shrinkage values tend to improve accuracy, but they also require more computational resources and training time. However, too small a shrinkage value can lead to overfitting, especially if n.trees is large.

n.trees: specifies the number of boosting iterations. Increasing the number of trees usually leads to better model performance.
Interaction depth: Interaction depth controls the depth of interaction between variables in the model. A higher interaction depth allows the model to capture more complex interactions between predictors, potentially leading to better performance. It's essential to carefully tune this parameter to find the optimal balance between model complexity and generalization performance.

Interactions:

Shrinkage and n.trees: These parameters often interact, as a smaller shrinkage value requires more trees to achieve the same level of accuracy. Thus, the optimal combination of shrinkage and n.trees depends on the specific dataset and the trade-off between computational resources and model performance.
Interaction depth and n.trees: Increasing the interaction depth may require more trees to capture the additional complexity introduced by interactions between predictors. Thus, the optimal combination of interaction depth and n.trees also depends on the dataset and the desired level of model complexity.
Shrinkage and interaction depth: Lower shrinkage values may allow for deeper interactions between variables, potentially influencing the optimal interaction depth. However, too low a shrinkage value can lead to overfitting, so it's essential to balance these parameters carefully.
"""





"""Q) If you look at the effect of interaction.depth, what would you conclude about the possible presence
of interactions in the QSAR dataset?

Ans:- Improvement with increasing interaction.depth: the model's performance (e.g., accuracy) improves as the interaction.depth increases, it suggests that the dataset contains complex interactions between predictors.
"""



best_params <- trained_model$bestTune

library(gbm)

response_train_binary <- ifelse(response_train == "RB", 1, 0)

gbm_model <- gbm(
  formula = response_train_binary ~ .,  # Define the formula for the model
  data = predictors_train,       # Training data
  distribution = "bernoulli",    # Distribution for classification
  n.trees = best_params$n.trees,              # Optimal number of trees
  interaction.depth = best_params$interaction.depth,  # Optimal interaction depth
  shrinkage = best_params$shrinkage               # Optimal shrinkage
)

print(gbm_model)

library(randomForest)
library(caret)


single_tree <- train(x = predictors_train, y = response_train, method = "rpart")


bagged <- train(x = predictors_train, y = response_train, method = "treebag")


random_forest <- train(x = predictors_train, y = response_train, method = "rf")


boosted_default <- train(x = predictors_train, y = response_train, method = "gbm")


pred_single_tree <- predict(single_tree, newdata = predictors_test, type = "prob")


pred_bagged <- predict(bagged, newdata = predictors_test, type = "prob")


pred_random_forest <- predict(random_forest, newdata = predictors_test, type = "prob")


pred_boosted_default <- predict(boosted_default, newdata = predictors_test, type = "prob")


brier_score_single_tree <- mean((response_test - pred_single_tree[, "RB"])^2)
misclassification_rate_single_tree <- mean(ifelse(response_test == "RB", 1, 0) != apply(pred_single_tree, 1, which.max))


brier_score_bagged <- mean((response_test - pred_bagged[, "RB"])^2)
misclassification_rate_bagged <- mean(ifelse(response_test == "RB", 1, 0) != apply(pred_bagged, 1, which.max))


brier_score_random_forest <- mean((response_test - pred_random_forest[, "RB"])^2)
misclassification_rate_random_forest <- mean(ifelse(response_test == "RB", 1, 0) != apply(pred_random_forest, 1, which.max))


brier_score_boosted_default <- mean((response_test - pred_boosted_default[, "RB"])^2)
misclassification_rate_boosted_default <- mean(ifelse(response_test == "RB", 1, 0) != apply(pred_boosted_default, 1, which.max))


cat("Brier Score for Single Tree:", brier_score_single_tree, "\n")
cat("Misclassification Rate for Single Tree:", misclassification_rate_single_tree, "\n")

cat("Brier Score for Bagged Ensemble:", brier_score_bagged, "\n")
cat("Misclassification Rate for Bagged Ensemble:", misclassification_rate_bagged, "\n")

cat("Brier Score for Random Forest Ensemble:", brier_score_random_forest, "\n")
cat("Misclassification Rate for Random Forest Ensemble:", misclassification_rate_random_forest, "\n")

cat("Brier Score for Boosted Ensemble (Default Settings):", brier_score_boosted_default, "\n")
cat("Misclassification Rate for Boosted Ensemble (Default Settings):", misclassification_rate_boosted_default, "\n")



predicted_probs <- predict(gbm_model, newdata = predictors_test, type = "response")

brier_score <- mean((response_test - predicted_probs)^2)


predicted_labels <- ifelse(predicted_probs >= 0.5, 1, 0)


misclassification_rate <- mean(predicted_labels != response_test)


cat("Brier Score:", brier_score, "\n")
cat("Misclassification Rate:", misclassification_rate, "\n")

