{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a30e2285-4cda-4a6f-9cae-6d4c9a8bce90",
   "metadata": {},
   "source": [
    "## Generating data using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da796cba-e3be-4495-a34c-364636d1444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975af3c1-0dea-444e-b135-7f33ba30b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_data(n):\n",
    "    p = 3\n",
    "    n1 = n2 = n // 2\n",
    "    cov_1 = np.eye(p) + 0.2\n",
    "    cov_2 = np.copy(cov_1)\n",
    "    cov_2[0, 1] = cov_2[1, 0] = cov_2[0, 1] + 0.5\n",
    "\n",
    "    mean_class1 = np.array([3] * p)\n",
    "    mean_class2 = np.array([2] * p)\n",
    "\n",
    "    x_class1 = np.random.multivariate_normal(mean_class1, cov_1, n1)\n",
    "    x_class2 = np.random.multivariate_normal(mean_class2, cov_2, n2)\n",
    "\n",
    "    x = np.vstack([x_class1, x_class2])\n",
    "    y = np.repeat([1, 2], [n1, n2])\n",
    "\n",
    "    df = pd.DataFrame(np.column_stack([x, y]), columns=[f'x{i}' for i in range(1, p+1)] + ['y'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830a33f3-8037-450e-942b-f9f499bfadc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set (Size 50):\n",
      "          x1        x2        x3    y\n",
      "0   2.544141  2.627882  2.481082  1.0\n",
      "1   2.080806  4.109955  3.776181  1.0\n",
      "2   5.382596  3.631755  3.296116  1.0\n",
      "3   2.986124  2.163454  1.668546  1.0\n",
      "4   1.636518  2.051159  3.207310  1.0\n",
      "5   5.068398  3.646277  4.319991  1.0\n",
      "6   3.340007  1.326764  2.154505  1.0\n",
      "7   4.839580  4.816918  3.528602  1.0\n",
      "8   1.247073  2.786365  4.292978  1.0\n",
      "9   4.938724  2.805459  3.408407  1.0\n",
      "10  3.526816  2.459638  2.454085  1.0\n",
      "11  3.495527  3.102929  3.364745  1.0\n",
      "12  2.816547  3.703979  5.286301  1.0\n",
      "13  2.917732  3.237356  4.574412  1.0\n",
      "14  2.827822  1.797380  3.751369  1.0\n",
      "15  3.826023  2.121357  3.734530  1.0\n",
      "16  2.021079  3.822270  1.516264  1.0\n",
      "17  3.368200  1.203428  2.949298  1.0\n",
      "18  4.218971  3.012775  0.678013  1.0\n",
      "19  2.422512  1.765429  3.763733  1.0\n",
      "20  4.082331  2.908635  2.649265  1.0\n",
      "21  2.472447  0.276598  3.037664  1.0\n",
      "22  4.266401  2.354535  2.967633  1.0\n",
      "23  3.893766  2.381152  5.079045  1.0\n",
      "24  1.365087  2.112895  3.056122  1.0\n",
      "25  1.274829  1.378251  1.290246  2.0\n",
      "26  3.304725  2.203670  1.402724  2.0\n",
      "27  2.308032  0.853769  1.524173  2.0\n",
      "28  1.293307  0.435195  1.532319  2.0\n",
      "29  2.004621  1.539055  3.327545  2.0\n",
      "30  2.019928  2.415653  4.012991  2.0\n",
      "31  2.730443  2.338263  3.369621  2.0\n",
      "32  1.862403  2.030645  4.009998  2.0\n",
      "33  2.600577  1.530362  1.452163  2.0\n",
      "34  0.892571  0.697143  1.684796  2.0\n",
      "35  1.010099  2.614119  2.134098  2.0\n",
      "36  1.388694  0.610084  3.781586  2.0\n",
      "37  1.334367  2.102479  0.936752  2.0\n",
      "38  2.274670  2.501908  3.722939  2.0\n",
      "39  2.471209  2.553371  1.964037  2.0\n",
      "40  2.702089  2.214372  1.383370  2.0\n",
      "41  0.317256  0.354073  1.826409  2.0\n",
      "42  1.516674  2.265922  2.393312  2.0\n",
      "43  2.296998  1.809118  0.832647  2.0\n",
      "44  3.344330  0.410890  2.987997  2.0\n",
      "45  1.607528  1.644166  1.945044  2.0\n",
      "46  1.957333  0.686227  2.779963  2.0\n",
      "47  2.937132  2.680044  3.133009  2.0\n",
      "48  3.233990  2.375284  4.218749  2.0\n",
      "49  1.871587  1.292795  0.450627  2.0\n",
      "\n",
      "Training Set (Size 10000):\n",
      "            x1        x2        x3    y\n",
      "0     4.519036  3.785223  3.206374  1.0\n",
      "1     0.983457  2.132963  2.109892  1.0\n",
      "2     3.526059  1.527830  1.555771  1.0\n",
      "3     4.279676  1.720976  2.970000  1.0\n",
      "4     3.474162  2.700623  2.187997  1.0\n",
      "...        ...       ...       ...  ...\n",
      "9995  2.746595  2.816788  4.218553  2.0\n",
      "9996  3.318706  3.355804  2.407337  2.0\n",
      "9997  0.406997  1.072181  0.167503  2.0\n",
      "9998  3.195631  3.250753  1.507991  2.0\n",
      "9999  1.709441  4.409701 -0.450639  2.0\n",
      "\n",
      "[10000 rows x 4 columns]\n",
      "\n",
      "Test Set (Size 10000):\n",
      "            x1        x2        x3    y\n",
      "0     3.246611  2.011988  3.885424  1.0\n",
      "1     2.964166  1.271876  2.052563  1.0\n",
      "2     1.481022  2.586816  1.867591  1.0\n",
      "3     1.195349  1.027224  1.875023  1.0\n",
      "4     3.902390  1.917725  1.920653  1.0\n",
      "...        ...       ...       ...  ...\n",
      "9995  0.452513 -0.003694  1.889758  2.0\n",
      "9996  1.328481  1.557830  0.048201  2.0\n",
      "9997  2.571358  0.089276  1.272826  2.0\n",
      "9998  1.721494  1.598419  2.028250  2.0\n",
      "9999  1.925912  2.422034  1.262268  2.0\n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "train_set_size_50 = gen_data(50)\n",
    "\n",
    "train_set_size_10000 = gen_data(10000)\n",
    "\n",
    "test_set_size_10000 = gen_data(10000)\n",
    "\n",
    "print(\"Training Set (Size 50):\")\n",
    "print(train_set_size_50)\n",
    "\n",
    "print(\"\\nTraining Set (Size 10000):\")\n",
    "print(train_set_size_10000)\n",
    "\n",
    "print(\"\\nTest Set (Size 10000):\")\n",
    "print(test_set_size_10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94433bf1-f425-4367-9e42-cd318762bc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dd1ad80-ccb7-4195-b1d5-c403e2f9562a",
   "metadata": {},
   "source": [
    "### Performance of models for the training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd7ef00-3038-4dd2-b665-8cd93259aa7c",
   "metadata": {},
   "source": [
    "### Small training set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f64f645-9667-44bd-b2ee-cdde0b4d44ae",
   "metadata": {},
   "source": [
    "QDA (Quadratic Discriminant Analysis):\n",
    "Bias:- QDA can capture more complex relationships in the data due to its flexibility, potentially leading to lower bias.\n",
    "Variance:- With a small training set, the model may overfit which result in higher variance.\n",
    "\n",
    "LDA (Linear Discriminant Analysis):\n",
    "Bias:- LDA assumes independence of features: often heavily violated, which may introduce bias. However, it is less prone to overfitting.\n",
    "Variance:- LDA assumes equal variances across classes than QDA and thus has less variance than QDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725eb6d8-52dc-4e77-9835-bea3e6eadcd2",
   "metadata": {},
   "source": [
    "### Large training set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49436eaa-42c8-4c15-81ec-00e4a1869aee",
   "metadata": {},
   "source": [
    "QDA:\n",
    "Bias: QDA can still capture complex relationships, potentially providing good performance.\n",
    "Variance: With more data, QDA may be better able to estimate the quadratric decision boundaries, reducing variance.\n",
    "\n",
    "LDA:\n",
    "Bias: LDA may have lower bias with a larger sample size.\n",
    "Variance: LDA is likely to maintain lower variance with a larger training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd175ab-cd38-43cc-98e8-f4943a21b40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bff7bb11-8375-4eb0-84d5-3b24e1e23c4b",
   "metadata": {},
   "source": [
    "## Building the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f791d09-4184-4728-bcf0-f9140ef84c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_qda_models(training_size, testing_size, no_of_repetitions):\n",
    "    Lda_results = []\n",
    "    Qda_results = []\n",
    "\n",
    "    for r in range(no_of_repetitions):\n",
    "        train_set = gen_data(training_size)\n",
    "        X_train = train_set.iloc[:, :-1]\n",
    "        y_train = train_set['y']\n",
    "\n",
    "        test_set = gen_data(testing_size)\n",
    "        X_test = test_set.iloc[:, :-1]\n",
    "        y_test = test_set['y']\n",
    "        \n",
    "        # LDA model\n",
    "        model_LDA = LinearDiscriminantAnalysis()\n",
    "        model_LDA.fit(X_train, y_train)\n",
    "        model_LDA_pred = model_LDA.predict(X_test)\n",
    "        Lda_scores = accuracy_score(y_test, model_LDA_pred)\n",
    "        Lda_results.append(Lda_scores)\n",
    "\n",
    "        # QDA model\n",
    "        model_QDA = QuadraticDiscriminantAnalysis()\n",
    "        model_QDA.fit(X_train, y_train)\n",
    "        model_QDA_pred = model_QDA.predict(X_test)\n",
    "        Qda_scores = accuracy_score(y_test, model_QDA_pred)\n",
    "        Qda_results.append(Qda_scores)\n",
    "\n",
    "    LDA_results_mean = np.mean(Lda_results)\n",
    "    QDA_results_mean = np.mean(Qda_results)\n",
    "\n",
    "    return LDA_results_mean, QDA_results_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31ccaf7-7e21-451d-bfa8-bf3beb6c5189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average LDA Accuracy (Training Set Size 50): 0.726415\n",
      "Average QDA Accuracy (Training Set Size 50): 0.723694\n",
      "\n",
      "Average LDA Accuracy (Training Set Size 10000): 0.7438429999999998\n",
      "Average QDA Accuracy (Training Set Size 10000): 0.7566740000000002\n"
     ]
    }
   ],
   "source": [
    "repetitions = 100\n",
    "train_size_50 = 50\n",
    "train_size_10000 = 10000\n",
    "test_size_10000 = 10000\n",
    "\n",
    "mean_LDA_train_50, mean_QDA_train_50 = lda_qda_models(train_size_50, test_size_10000, repetitions)\n",
    "mean_LDA_train_10000, mean_QDA_train_10000 = lda_qda_models(train_size_10000, test_size_10000, repetitions)\n",
    "\n",
    "print(f\"Average LDA Accuracy (Training Set Size 50): {mean_LDA_train_50}\")\n",
    "print(f\"Average QDA Accuracy (Training Set Size 50): {mean_QDA_train_50}\")\n",
    "\n",
    "print(f\"\\nAverage LDA Accuracy (Training Set Size 10000): {mean_LDA_train_10000}\")\n",
    "print(f\"Average QDA Accuracy (Training Set Size 10000): {mean_QDA_train_10000}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb235f7-4644-4144-9de8-080e7541b8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cffe2b4-6c76-41c9-9484-2e958aa8f0f0",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "303f946c-db9e-4669-bac7-bd964fe94dea",
   "metadata": {},
   "source": [
    "Training Set Size 50:\n",
    "The QDA accuracy (0.723) is slightly lower than the LDA accuracy (0.728). This does agree with our expectations, as QDA tends to have higher variance thus with a small training set, it might overfit more than LDA.\n",
    "\n",
    "Training Set Size 10000:\n",
    "The QDA accuracy (0.757) is higher than the LDA accuracy (0.744). This also does agree with our expectations, as QDA's flexibility may be beneficial when the training set is larger, allowing it to capture more complex patterns and potentially outperform LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1adf7-d329-4e00-9ea4-85619d2ade63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b845103-5e6a-49b8-9a38-21932c90e950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac247f73-b78c-405a-8d15-40772eecb87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f36571-5404-4ed1-a30e-91d71f443330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba89f2f-afce-4aa4-a78d-65054470d65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e89f4d-7990-4f7b-b3db-9a7852f4f9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0b452-b5ad-4ac2-950e-5b7327392cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07775f36-9612-42bc-b705-11b47ee0b483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db061cf-4023-4d0e-8e82-e0148e553c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3654aa-d56b-4791-b261-deaedb6a93ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
